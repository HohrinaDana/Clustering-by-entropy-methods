В отличие от классических методов кластеризации, которые опираются на Евклидово расстояние, данный алгоритм использует энтропию Шеннона и взаимную информацию. Это делает его идеальным для работы с категориальным) данными.
Проект выполнен в рамках курсовой работы по дисциплине «Методы оптимизации». 

Ключевые понятия
– НИП (Наиболее Информативный Признак) — атрибут, обладающий максимальной суммарной связью со всеми остальными признаками датасета.
– НИЗ (Наиболее Информативное Значение) — конкретное значение НИП, которое максимально снижает неопределенность системы при выделении его в отдельный кластер.
– Коэффициент однородности — метрика качества кластера, оценивающая чистоту группы по совокупности всех признаков.

Технологии:
Python
Pandas — обработка и фильтрация данных.
NumPy — векторные вычисления энтропии.
Matplotlib — визуализация результатов и оценка однородности.

Как это работает:
Алгоритм является итеративным и жадным: Находит НИП в текущем наборе данных.Внутри НИП находит лучшее значение (НИЗ).Формирует кластер из объектов, обладающих этим значением.Рассчитывает однородность u.Удаляет выделенные объекты из общей выборки и повторяет процесс для остатка.

Пример результатов (Mushroom Dataset):
Алгоритм был протестирован на наборе данных о грибах. Без предварительного знания о целевом классе (съедобный/ядовитый), программа смогла выделить кластеры с высокой однородностью (u > 0.8), которые практически на 100% состояли из представителей одного класса.
